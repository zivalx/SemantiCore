# SemantiCore

**An Ontology-First Semantic Graph Platform**

Transform heterogeneous raw data into queryable semantic graphs through a transparent, human-in-the-loop ontology design process.

---

## Philosophy

This is **not** a toy demo. This is a serious showcase of how semantic systems should be built:

### Core Principles

1. **Ontology is a first-class artifact** â€” not an afterthought
   - Stored explicitly in Neo4j as a graph structure
   - Versioned and traceable
   - Independent of instance data

2. **Explicit uncertainty** â€” the system represents what it doesn't know
   - Confidence scores with reasoning
   - Alternative interpretations
   - Open questions for human input

3. **LLMs propose, humans decide** â€” AI assists, humans control
   - Every ontology element is reviewed
   - Feedback shapes iterations
   - No black-box automation

4. **Full traceability** â€” every decision has provenance
   - Semantic elements link to source data
   - Ontology changes are versioned
   - Query translations are visible

5. **Transparency beats automation** â€” clarity over magic
   - See the generated Cypher
   - Understand confidence scores
   - Review LLM reasoning

---

## What This System Does

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Data    â”‚ CSV, JSON, Text, PDF, DOCX
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Canonical   â”‚ Normalized intermediate format
â”‚ Records     â”‚ (Provenance preserved)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Domain      â”‚ Human describes the domain
â”‚ Description â”‚ in natural language
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ontology    â”‚ LLM proposes classes & relationships
â”‚ Proposal    â”‚ (with explanations, confidence, alternatives)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Human       â”‚ Accept / Modify / Request revision
â”‚ Feedback    â”‚ Iterate until satisfied
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Accepted    â”‚ Ontology stored in Neo4j
â”‚ Ontology    â”‚ (versioned, traceable)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Instance    â”‚ Data materialized as graph
â”‚ Graph       â”‚ according to ontology
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Natural     â”‚ Ask questions, get Cypher,
â”‚ Language    â”‚ see results (transparently)
â”‚ Queries     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture

### Two UI Options

This project provides **two complete UI implementations**:

#### 1. **Streamlit UI** (Simple, All-in-One)
- Single-page app with wizard workflow
- Perfect for local development and demos
- Branded as "SemantiCore" in the interface
- Connects directly to Neo4j

#### 2. **React + FastAPI** (Production-Ready)
- Modern TypeScript frontend with Vite
- RESTful API backend with FastAPI
- PostgreSQL for application state + Neo4j for knowledge graph
- Docker Compose orchestration
- Scalable and production-ready

### Tech Stack

**Core:**
- **Python 3.11** â€” Modern Python with type hints
- **Neo4j Community Edition 5.15** â€” Knowledge graph storage
- **Pydantic** â€” Data validation and serialization
- **LLM APIs** â€” Claude (Anthropic) or GPT-4 (OpenAI)

**Streamlit UI:**
- **Streamlit** â€” Interactive Python UI
- Direct Neo4j connection

**React + API Stack:**
- **FastAPI** â€” High-performance Python REST API
- **PostgreSQL 15** â€” Application state (projects, jobs, sources)
- **React 19** â€” Modern UI framework
- **TypeScript 5** â€” Type-safe frontend
- **Vite** â€” Fast build tooling
- **D3.js** â€” Graph visualizations
- **Docker Compose** â€” Multi-service orchestration

### Project Structure

```
semantic_mapper/
â”œâ”€â”€ src/semantic_mapper/          # Core Python package
â”‚   â”œâ”€â”€ models/                   # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ primitives.py         # Semantic candidates
â”‚   â”‚   â”œâ”€â”€ ontology.py           # Ontology structures
â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Data ingestion models
â”‚   â”‚   â”œâ”€â”€ proposal.py           # LLM proposals
â”‚   â”‚   â””â”€â”€ feedback.py           # Human feedback
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                # Data ingesters
â”‚   â”‚   â”œâ”€â”€ csv_ingester.py       # CSV data ingestion
â”‚   â”‚   â”œâ”€â”€ json_ingester.py      # JSON data ingestion
â”‚   â”‚   â”œâ”€â”€ text_ingester.py      # Plain text ingestion
â”‚   â”‚   â”œâ”€â”€ pdf_ingester.py       # PDF document ingestion
â”‚   â”‚   â””â”€â”€ docx_ingester.py      # DOCX document ingestion
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                    # Neo4j operations
â”‚   â”‚   â”œâ”€â”€ connection.py         # Connection management
â”‚   â”‚   â”œâ”€â”€ ontology_ops.py       # Ontology CRUD
â”‚   â”‚   â”œâ”€â”€ instance_ops.py       # Instance materialization
â”‚   â”‚   â””â”€â”€ query_ops.py          # Query execution
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                      # LLM integration
â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py # Claude integration
â”‚   â”‚   â”œâ”€â”€ openai_provider.py    # GPT integration
â”‚   â”‚   â”œâ”€â”€ factory.py            # Provider factory
â”‚   â”‚   â”œâ”€â”€ ontology_proposer.py  # Ontology generation
â”‚   â”‚   â””â”€â”€ query_translator.py   # NL â†’ Cypher translation
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/               # Semantic extraction
â”‚   â”‚   â””â”€â”€ extractor.py          # Primitive extraction
â”‚   â”‚
â”‚   â””â”€â”€ ui/                       # Streamlit UI
â”‚       â”œâ”€â”€ app.py                # Main SemantiCore app
â”‚       â””â”€â”€ pages/                # UI pages
â”‚           â”œâ”€â”€ query.py          # Query interface
â”‚           â””â”€â”€ settings.py       # Settings page
â”‚
â”œâ”€â”€ backend/                      # FastAPI backend (optional)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI application
â”‚   â”‚   â”œâ”€â”€ dependencies.py       # Shared dependencies
â”‚   â”‚   â”œâ”€â”€ routers/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ projects.py       # Project management
â”‚   â”‚   â”‚   â”œâ”€â”€ sources.py        # Data source management
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py           # Background job tracking
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction.py     # Semantic extraction API
â”‚   â”‚   â”‚   â”œâ”€â”€ ontology.py       # Ontology operations
â”‚   â”‚   â”‚   â”œâ”€â”€ materialization.py # Graph materialization
â”‚   â”‚   â”‚   â””â”€â”€ query.py          # Query execution
â”‚   â”‚   â””â”€â”€ models/               # Request/response models
â”‚   â”œâ”€â”€ db/                       # PostgreSQL database
â”‚   â”‚   â”œâ”€â”€ connection.py         # DB connection
â”‚   â”‚   â””â”€â”€ models.py             # SQLAlchemy models
â”‚   â”œâ”€â”€ services/                 # Business logic
â”‚   â”‚   â”œâ”€â”€ extraction_service.py
â”‚   â”‚   â”œâ”€â”€ ontology_service.py
â”‚   â”‚   â”œâ”€â”€ materialization_service.py
â”‚   â”‚   â””â”€â”€ query_service.py
â”‚   â”œâ”€â”€ config.py                 # Configuration
â”‚   â”œâ”€â”€ Dockerfile                # Backend container
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ frontend/                     # React frontend (optional)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx               # Main React app
â”‚   â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”œâ”€â”€ types.ts              # TypeScript types
â”‚   â”‚   â””â”€â”€ constants.tsx         # App constants
â”‚   â”œâ”€â”€ Dockerfile                # Frontend container
â”‚   â”œâ”€â”€ nginx.conf                # Nginx configuration
â”‚   â”œâ”€â”€ package.json              # Node dependencies
â”‚   â””â”€â”€ vite.config.ts            # Vite configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw data files
â”‚   â””â”€â”€ examples/                 # Example datasets
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ QUICK_START.md
â”‚   â”œâ”€â”€ USAGE_GUIDE.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ ARCHITECTURE.md
â”‚
â”œâ”€â”€ tests/                        # Tests
â”œâ”€â”€ docker-compose.yml            # Full-stack orchestration
â”œâ”€â”€ .env.example                  # Environment template
â””â”€â”€ README.md
```

### Database Architecture

**Dual-Database Design:**

1. **PostgreSQL** (Application State)
   - Projects, jobs, data sources
   - User workflow tracking
   - Background job status
   - Used by: FastAPI backend

2. **Neo4j** (Knowledge Graph)
   - Ontology schema (classes, relationships)
   - Instance data (entities, relations)
   - Ontology versioning
   - Query execution
   - Used by: Both Streamlit and FastAPI

---

## Installation

### Prerequisites

**For Streamlit UI:**
- Python 3.11+
- Neo4j Community Edition 5.15+
- API Keys (Anthropic or OpenAI)

**For React + API:**
- Python 3.11+
- Node.js 18+
- Docker & Docker Compose (recommended)
- PostgreSQL 15+
- Neo4j Community Edition 5.15+
- API Keys (Anthropic or OpenAI)

### Setup

```bash
# Clone the repository
git clone <repository-url>
cd semantic_mapper

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e .

# Copy environment template
cp .env.example .env

# Edit .env with your settings:
# - Database credentials
# - LLM API keys
nano .env  # or use your favorite editor
```

### Configure Databases

#### Neo4j (Required for both UIs)

**Option 1: Docker (Recommended)**
```bash
docker run -d --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/your_password \
  neo4j:5.15-community
```

**Option 2: Neo4j Desktop**
1. Install Neo4j Desktop
2. Create a new database
3. Start the database
4. Note connection details (default: bolt://localhost:7687)

#### PostgreSQL (Only for React + API)

**Option 1: Docker (Recommended)**
```bash
docker run -d --name postgres \
  -p 5432:5432 \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=semantic_mapper \
  postgres:15-alpine
```

**Option 2: Local Installation**
- Install PostgreSQL 15+
- Create database: `createdb semantic_mapper`

### Configure LLM

Choose **Anthropic** (recommended) or **OpenAI**:

```bash
# For Anthropic Claude
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# OR for OpenAI
LLM_PROVIDER=openai
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=gpt-4-turbo-preview
```

---

## Quick Start

### Option 1: Streamlit UI (Simplest)

Perfect for local development, demos, and single-user scenarios.

```bash
# Activate virtual environment
source venv/bin/activate  # Windows: venv\Scripts\activate

# Run Streamlit app
streamlit run src/semantic_mapper/ui/app.py
```

**Access:** http://localhost:8501

**Features:**
- SemantiCore branded interface
- Full wizard workflow (8 steps)
- Project management
- Direct Neo4j integration
- Query interface with natural language â†’ Cypher translation

### Option 2: React + FastAPI (Production)

Full-stack architecture with REST API, React frontend, and dual databases.

**Using Docker Compose (Recommended):**
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

**Services:**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Neo4j Browser: http://localhost:7474
- PostgreSQL: localhost:5432

**Manual Setup (Development):**
```bash
# Terminal 1: Start backend
cd backend
pip install -r requirements.txt
uvicorn api.main:app --reload

# Terminal 2: Start frontend
cd frontend
npm install
npm run dev

# Terminal 3: Ensure databases are running
# Neo4j on port 7687
# PostgreSQL on port 5432
```

---

## Usage Workflows

### Streamlit Workflow

1. **Open App** â†’ http://localhost:8501
2. **Hub Overview** â†’ View existing projects
3. **New Deployment** â†’ Start wizard:
   - **Step 1: Identity** â†’ Project name
   - **Step 2: Frame** â†’ Domain description
   - **Step 3: Ingest** â†’ Upload data files
   - **Step 4: Extract** â†’ Review primitives
   - **Step 5: Propose** â†’ Review ontology
   - **Step 6: Negotiate** â†’ Commit blueprint
   - **Step 7: Knowledge** â†’ Visualize graph
   - **Step 8: Query** â†’ Query with natural language

4. **Query Interface** â†’ Natural language or Cypher queries
5. **Settings** â†’ Configure LLM and Neo4j

### React + API Workflow

1. **Open App** â†’ http://localhost:3000
2. **Create Project** â†’ Define project and domain
3. **Upload Data** â†’ Add CSV, JSON, text, PDF, or DOCX files
4. **Extract Primitives** â†’ AI extracts semantic elements
5. **Review Ontology** â†’ Accept, modify, or request revisions
6. **Materialize Graph** â†’ Create instances in Neo4j
7. **Query Data** â†’ Natural language or Cypher queries
8. **API Access** â†’ Use REST API at http://localhost:8000/docs

---

## API Documentation

The FastAPI backend provides comprehensive REST endpoints:

### Projects
- `POST /api/projects` - Create new project
- `GET /api/projects` - List all projects
- `GET /api/projects/{id}` - Get project details
- `DELETE /api/projects/{id}` - Delete project

### Data Sources
- `POST /api/sources` - Upload data source
- `GET /api/sources` - List sources for project
- `GET /api/sources/{id}` - Get source details

### Extraction
- `POST /api/extraction/extract` - Extract semantic primitives
- `GET /api/extraction/results/{job_id}` - Get extraction results

### Ontology
- `POST /api/ontology/propose` - Generate ontology proposal
- `GET /api/ontology/{id}` - Get ontology details
- `POST /api/ontology/{id}/feedback` - Submit human feedback
- `PUT /api/ontology/{id}/accept` - Accept and store ontology

### Materialization
- `POST /api/materialization/materialize` - Create graph instances
- `GET /api/materialization/status/{job_id}` - Check job status

### Query
- `POST /api/query/translate` - Translate NL to Cypher
- `POST /api/query/execute` - Execute Cypher query
- `GET /api/query/schema/{ontology_id}` - Get ontology schema

**Full API Documentation:** http://localhost:8000/docs (when backend is running)

---

## Ontology Storage in Neo4j

The ontology itself is stored as a graph:

```cypher
// Ontology structure
(Ontology)-[:DEFINES]->(OntologyClass)
(Ontology)-[:DEFINES]->(OntologyRelationType)

(OntologyClass)-[:CAN_RELATE_VIA]->(OntologyRelationType)
(OntologyRelationType)-[:TARGETS]->(OntologyClass)

// Instances
(Instance)-[:INSTANCE_OF]->(OntologyClass)
(Instance)-[RELATED {type: "REL_NAME"}]->(Instance)
```

This allows:
- Querying the ontology itself
- Versioning and tracking changes
- Storing rejected alternatives
- Full provenance

---

## Key Features

### âœ… Implemented

- âœ… Multi-format data ingestion (CSV, JSON, text, PDF, DOCX)
- âœ… Canonical normalization with provenance
- âœ… LLM-based ontology proposal
- âœ… Confidence scores with reasoning
- âœ… Human-in-the-loop feedback
- âœ… Ontology storage in Neo4j
- âœ… Ontology versioning
- âœ… Natural language query translation
- âœ… Transparent Cypher generation
- âœ… Two complete UI implementations (Streamlit + React)
- âœ… RESTful API with FastAPI
- âœ… Dual-database architecture (PostgreSQL + Neo4j)
- âœ… Docker Compose orchestration

### ğŸš§ Intentionally Simplified

These are **not** missing features â€” they're deliberately simplified to maintain transparency:

- **Automatic instance materialization** â€” Requires complex LLM-based mapping
- **Relationship extraction** â€” Needs NLP and entity resolution
- **Conflict resolution** â€” Human decisions needed
- **Entity deduplication** â€” Domain-specific logic required

### ğŸ”® Future Enhancements

- Visual ontology graph editor
- Ontology diff viewer
- Batch instance import with LLM mapping
- Query result visualization
- Export to OWL/RDF
- Multi-user collaboration
- Advanced graph algorithms

---

## Design Decisions & Limitations

### What This System IS

- âœ… A platform for **ontology-first** semantic modeling
- âœ… A **human-in-the-loop** system for data transformation
- âœ… A **transparent** alternative to black-box knowledge graphs
- âœ… A **production-quality scaffold** ready for extension

### What This System IS NOT

- âŒ A fully automated knowledge graph builder
- âŒ An entity resolution system
- âŒ A pre-built domain ontology (you create your own)
- âŒ A replacement for human domain expertise

### Key Limitations

1. **Manual instance creation** â€” Automatic mapping requires domain-specific rules
2. **English only** â€” LLM prompts are in English
3. **Single-user Streamlit** â€” No collaboration features in Streamlit UI
4. **React UI in development** â€” Full feature parity still being developed

### Why These Limitations?

Because **transparency beats automation**. It's better to show what the system *can't* do than to hide it behind automation and pretend everything works.

---

## Examples

See `data/examples/` for:

1. **E-commerce dataset** (CSV) â€” Orders, customers, products
2. **Research papers** (JSON) â€” Paper metadata and citations
3. **Clinical trials** (PDF) â€” Trial eligibility criteria
4. **Product events** (JSON) â€” Usage analytics events

---

## Development

### Run Tests

```bash
pytest tests/
```

### Code Quality

```bash
# Format
black src/ backend/

# Lint
ruff check src/ backend/

# Type check
mypy src/ backend/
```

### Frontend Development

```bash
cd frontend
npm run dev       # Development server
npm run build     # Production build
npm run preview   # Preview production build
```

---

## Deployment

### Streamlit (Simple)

**Railway:**
```bash
railway up
```

**Render:**
- Connect GitHub repository
- Set build command: `pip install -e .`
- Set start command: `streamlit run src/semantic_mapper/ui/app.py`

### React + API (Production)

**Docker Compose (Any Platform):**
```bash
docker-compose up -d
```

**Kubernetes:**
See `docs/DEPLOYMENT.md` for Kubernetes manifests.

**Cloud Platforms:**
- AWS ECS with RDS and Managed Neo4j
- Google Cloud Run with Cloud SQL and Neo4j Aura
- Azure Container Instances with Azure Database

---

## Philosophy Deep Dive

### Why Ontology-First?

Most data systems treat ontology as an afterthought:
1. Build the database
2. Write queries
3. Maybe document the schema later

This system inverts that:
1. **Define ontology** (with human oversight)
2. **Map data** to ontology
3. **Query semantically** (not just syntactically)

### Why Human-in-the-Loop?

LLMs are powerful but not infallible. For serious systems:
- Humans understand **domain context**
- Humans make **strategic decisions**
- Humans accept **responsibility**

LLMs should **assist**, not **replace**.

### Why Two UIs?

- **Streamlit:** Quick prototyping, demos, single-user workflows
- **React + API:** Production deployments, multi-user, integrations

Choose the right tool for your use case!

### Why Transparency?

"AI-powered" often means "black box." This system shows:
- **How** decisions are made
- **Why** with confidence scores
- **What** alternatives exist

You can trust what you can inspect.

---

## Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines.

**Areas for improvement:**
- Additional data formats (Excel, XML, SQL dumps)
- Better visualization (graph rendering, ontology diagrams)
- Advanced query features (aggregations, graph algorithms)
- Entity resolution and deduplication
- Automatic relationship extraction
- Multi-language support
- React UI feature completion

**Development setup:**
```bash
# Install dev dependencies
pip install -e ".[dev]"

# Frontend dev dependencies
cd frontend && npm install

# Run tests
pytest tests/

# Code quality
black src/ backend/ && ruff src/ backend/ && mypy src/ backend/
```

---

## License

MIT License â€” See LICENSE file

---

## Acknowledgments

Built on the shoulders of giants:
- Neo4j for graph database
- Anthropic/OpenAI for LLMs
- Pydantic for data validation
- Streamlit for rapid prototyping
- FastAPI for high-performance APIs
- React for modern UI development

---

## Contact

Questions? Ideas? Open an issue or discussion!

**Remember:** This system helps humans formalize meaning. It doesn't pretend to "understand" your domain â€” that's your job. It just makes the process explicit, traceable, and iterative.
