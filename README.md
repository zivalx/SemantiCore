# Semantic Mapper

**An Ontology-First Semantic Graph Platform**

Transform heterogeneous raw data into queryable semantic graphs through a transparent, human-in-the-loop ontology design process.

---

## Philosophy

This is **not** a toy demo. This is a serious showcase of how semantic systems should be built:

### Core Principles

1. **Ontology is a first-class artifact** â€” not an afterthought
   - Stored explicitly in Neo4j as a graph structure
   - Versioned and traceable
   - Independent of instance data

2. **Explicit uncertainty** â€” the system represents what it doesn't know
   - Confidence scores with reasoning
   - Alternative interpretations
   - Open questions for human input

3. **LLMs propose, humans decide** â€” AI assists, humans control
   - Every ontology element is reviewed
   - Feedback shapes iterations
   - No black-box automation

4. **Full traceability** â€” every decision has provenance
   - Semantic elements link to source data
   - Ontology changes are versioned
   - Query translations are visible

5. **Transparency beats automation** â€” clarity over magic
   - See the generated Cypher
   - Understand confidence scores
   - Review LLM reasoning

---

## What This System Does

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Data    â”‚ CSV, JSON, Text, PDF, DOCX
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Canonical   â”‚ Normalized intermediate format
â”‚ Records     â”‚ (Provenance preserved)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Domain      â”‚ Human describes the domain
â”‚ Description â”‚ in natural language
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ontology    â”‚ LLM proposes classes & relationships
â”‚ Proposal    â”‚ (with explanations, confidence, alternatives)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Human       â”‚ Accept / Modify / Request revision
â”‚ Feedback    â”‚ Iterate until satisfied
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Accepted    â”‚ Ontology stored in Neo4j
â”‚ Ontology    â”‚ (versioned, traceable)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Instance    â”‚ Data materialized as graph
â”‚ Graph       â”‚ according to ontology
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Natural     â”‚ Ask questions, get Cypher,
â”‚ Language    â”‚ see results (transparently)
â”‚ Queries     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture

### Tech Stack

- **Python 3.11** â€” Modern Python with type hints
- **Neo4j Community Edition** â€” Graph database (local)
- **Streamlit** â€” Interactive UI
- **Pydantic** â€” Data validation and serialization
- **Neo4j Python Driver** â€” Official driver
- **LLM APIs** â€” Claude (Anthropic) or GPT-4 (OpenAI)

### Project Structure

```
semantic_mapper/
â”œâ”€â”€ src/semantic_mapper/
â”‚   â”œâ”€â”€ models/              # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ primitives.py    # Semantic candidates
â”‚   â”‚   â”œâ”€â”€ ontology.py      # Ontology structures
â”‚   â”‚   â”œâ”€â”€ ingestion.py     # Data ingestion models
â”‚   â”‚   â”œâ”€â”€ proposal.py      # LLM proposals
â”‚   â”‚   â””â”€â”€ feedback.py      # Human feedback
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/           # Data ingesters
â”‚   â”‚   â”œâ”€â”€ csv_ingester.py
â”‚   â”‚   â”œâ”€â”€ json_ingester.py
â”‚   â”‚   â”œâ”€â”€ text_ingester.py
â”‚   â”‚   â”œâ”€â”€ pdf_ingester.py
â”‚   â”‚   â””â”€â”€ docx_ingester.py
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/               # Neo4j operations
â”‚   â”‚   â”œâ”€â”€ connection.py    # Connection management
â”‚   â”‚   â”œâ”€â”€ ontology_ops.py  # Ontology CRUD
â”‚   â”‚   â”œâ”€â”€ instance_ops.py  # Instance materialization
â”‚   â”‚   â””â”€â”€ query_ops.py     # Query execution
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                 # LLM integration
â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â”œâ”€â”€ ontology_proposer.py
â”‚   â”‚   â””â”€â”€ query_translator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/          # Semantic extraction
â”‚   â”‚   â””â”€â”€ extractor.py     # Analysis utilities
â”‚   â”‚
â”‚   â””â”€â”€ ui/                  # Streamlit UI
â”‚       â”œâ”€â”€ app.py           # Main app
â”‚       â””â”€â”€ pages/           # UI pages
â”‚           â”œâ”€â”€ 1_upload_data.py
â”‚           â”œâ”€â”€ 2_define_domain.py
â”‚           â”œâ”€â”€ 3_review_ontology.py
â”‚           â”œâ”€â”€ 4_materialize_graph.py
â”‚           â”œâ”€â”€ 5_query_data.py
â”‚           â””â”€â”€ 6_settings.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw data files
â”‚   â””â”€â”€ examples/            # Example datasets
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ tests/                   # Tests
â””â”€â”€ config/                  # Configuration files
```

---

## Installation

### Prerequisites

1. **Python 3.11+**
2. **Neo4j Community Edition** (local instance)
3. **API Keys** (Anthropic or OpenAI)

### Setup

```bash
# Clone the repository
git clone <repository-url>
cd semantic_mapper

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e .

# Copy environment template
cp .env.example .env

# Edit .env with your settings
# - Neo4j credentials
# - LLM API keys
```

### Configure Neo4j

1. Install Neo4j Desktop or Community Edition
2. Create a new database
3. Start the database
4. Note the connection details (default: bolt://localhost:7687)
5. Update `.env` with credentials

### Configure LLM

Choose **Anthropic** (recommended) or **OpenAI**:

```bash
# For Anthropic Claude
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# OR for OpenAI
LLM_PROVIDER=openai
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=gpt-4-turbo-preview
```

---

## Quick Start

### Three Ways to Run

**1. Easy Start (Recommended)**
```bash
# Unix/Mac/Linux
./scripts/start.sh

# Windows
scripts\start.bat
```

**2. Docker**
```bash
docker-compose up -d
```
Access at http://localhost:8501

**3. Manual**
```bash
streamlit run src/semantic_mapper/ui/app.py
```

### 5-Minute Example

```bash
# 1. Start the app (use one of the methods above)
# 2. Upload data/examples/ecommerce_orders.csv
# 3. Describe domain: "E-commerce orders with customers and products"
# 4. Generate ontology proposal (wait 30-60 sec)
# 5. Review and accept
# 6. Create sample instances
# 7. Query: "How many orders are there?"
```

---

## Documentation

- **[Quick Start](docs/QUICK_START.md)** â€” Get running in 10 minutes
- **[Usage Guide](docs/USAGE_GUIDE.md)** â€” Comprehensive examples for every feature
- **[Deployment Guide](docs/DEPLOYMENT.md)** â€” Local, Docker, and cloud deployment
- **[Architecture](docs/ARCHITECTURE.md)** â€” Technical deep dive
- **[Contributing](CONTRIBUTING.md)** â€” Development guidelines and standards

---

## Basic Workflow

#### 1. Upload Data

- Navigate to **Upload Data**
- Upload CSV, JSON, text, PDF, or DOCX files
- Data is converted to canonical format
- No semantic interpretation yet

#### 2. Define Domain

- Navigate to **Define Domain**
- Describe your domain in natural language
- Example:

  ```
  This data represents an e-commerce system with customers,
  orders, and products. Customers place orders containing
  multiple items. Products belong to categories.
  ```

- Click **Generate Proposal**
- Wait 30-60 seconds for LLM to analyze and propose

#### 3. Review Ontology

- Navigate to **Review Ontology**
- Examine proposed classes and relationships
- Review confidence scores and explanations
- **Options:**
  - âœ… **Accept** â€” Save to Neo4j and proceed
  - âœï¸ **Request Modifications** â€” Provide feedback for next iteration
  - ğŸ”„ **Request New Proposal** â€” Start over with guidance

#### 4. Materialize Graph (Manual)

- Navigate to **Materialize Graph**
- Create sample instances of ontology classes
- In production, this would use LLM for automatic mapping

#### 5. Query Data

- Navigate to **Query Data**
- **Natural Language Mode:**
  - Ask questions in plain English
  - See the generated Cypher query
  - Review explanation and concepts used
  - Execute and see results
- **Direct Cypher Mode:**
  - Write Cypher directly
  - Execute and see results

---

## Ontology Storage in Neo4j

The ontology itself is stored as a graph:

```cypher
// Ontology structure
(Ontology)-[:DEFINES]->(OntologyClass)
(Ontology)-[:DEFINES]->(OntologyRelationType)

(OntologyClass)-[:CAN_RELATE_VIA]->(OntologyRelationType)
(OntologyRelationType)-[:TARGETS]->(OntologyClass)

// Instances
(Instance)-[:INSTANCE_OF]->(OntologyClass)
(Instance)-[RELATED {type: "REL_NAME"}]->(Instance)
```

This allows:
- Querying the ontology itself
- Versioning and tracking changes
- Storing rejected alternatives
- Full provenance

---

## Key Features

### âœ… Implemented

- âœ… Multi-format data ingestion (CSV, JSON, text, PDF, DOCX)
- âœ… Canonical normalization with provenance
- âœ… LLM-based ontology proposal
- âœ… Confidence scores with reasoning
- âœ… Human-in-the-loop feedback
- âœ… Ontology storage in Neo4j
- âœ… Ontology versioning
- âœ… Natural language query translation
- âœ… Transparent Cypher generation
- âœ… Interactive Streamlit UI

### ğŸš§ Intentionally Simplified

These are **not** missing features â€” they're deliberately simplified to maintain transparency:

- **Automatic instance materialization** â€” Requires complex LLM-based mapping
- **Relationship extraction** â€” Needs NLP and entity resolution
- **Conflict resolution** â€” Human decisions needed
- **Entity deduplication** â€” Domain-specific logic required

### ğŸ”® Future Enhancements

- Visual ontology graph editor
- Ontology diff viewer
- Batch instance import with LLM mapping
- Query result visualization
- Export to OWL/RDF
- Multi-user collaboration

---

## Design Decisions & Limitations

### What This System IS

- âœ… A platform for **ontology-first** semantic modeling
- âœ… A **human-in-the-loop** system for data transformation
- âœ… A **transparent** alternative to black-box knowledge graphs
- âœ… A **production-quality scaffold** ready for extension

### What This System IS NOT

- âŒ A fully automated knowledge graph builder
- âŒ An entity resolution system
- âŒ A pre-built domain ontology (you create your own)
- âŒ A replacement for human domain expertise

### Key Limitations

1. **Manual instance creation** â€” Automatic mapping requires domain-specific rules
2. **Single-user** â€” No collaboration features yet
3. **English only** â€” LLM prompts are in English

### Why These Limitations?

Because **transparency beats automation**. It's better to show what the system *can't* do than to hide it behind automation and pretend everything works.

---

## Examples

See `data/examples/` for:

1. **E-commerce dataset** (CSV) â€” Orders, customers, products
2. **Research papers** (PDF) â€” Academic paper metadata
3. **JSON API responses** â€” Nested data structures
4. **Ontology evolution** â€” v1 â†’ v2 with feedback

---

## Development

### Run Tests

```bash
pytest tests/
```

### Code Quality

```bash
# Format
black src/

# Lint
ruff src/

# Type check
mypy src/
```

---

## Philosophy Deep Dive

### Why Ontology-First?

Most data systems treat ontology as an afterthought:
1. Build the database
2. Write queries
3. Maybe document the schema later

This system inverts that:
1. **Define ontology** (with human oversight)
2. **Map data** to ontology
3. **Query semantically** (not just syntactically)

### Why Human-in-the-Loop?

LLMs are powerful but not infallible. For serious systems:
- Humans understand **domain context**
- Humans make **strategic decisions**
- Humans accept **responsibility**

LLMs should **assist**, not **replace**.

### Why Transparency?

"AI-powered" often means "black box." This system shows:
- **How** decisions are made
- **Why** with confidence scores
- **What** alternatives exist

You can trust what you can inspect.

---

## Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines.

**Areas for improvement:**
- Additional data formats (Excel, XML, SQL dumps)
- Better visualization (graph rendering, ontology diagrams)
- Advanced query features (aggregations, graph algorithms)
- Entity resolution and deduplication
- Automatic relationship extraction
- Multi-language support

**Development setup:**
```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Code quality
black src/ && ruff src/ && mypy src/
```

---

## License

MIT License â€” See LICENSE file

---

## Acknowledgments

Built on the shoulders of giants:
- Neo4j for graph database
- Anthropic/OpenAI for LLMs
- Pydantic for data validation
- Streamlit for rapid UI development

---

## Contact

Questions? Ideas? Open an issue or discussion!

**Remember:** This system helps humans formalize meaning. It doesn't pretend to "understand" your domain â€” that's your job. It just makes the process explicit, traceable, and iterative.
